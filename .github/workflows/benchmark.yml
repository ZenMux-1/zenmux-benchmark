# ZenMux HLE Benchmark GitHub Actions Workflow
name: ZenMux HLE Benchmark

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Evaluation mode'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - single
          - filter
      model_config:
        description: 'Model config: For single mode use "model_slug:provider_slug", for filter mode use filter string'
        required: false
        default: ''
      exclude_models:
        description: 'Exclude models (comma-separated, e.g., "anthropic,openai/gpt-4o")'
        required: false
        default: ''
      exclude_providers:
        description: 'Exclude providers (comma-separated, e.g., "theta,openai")'
        required: false
        default: ''
      text_only:
        description: 'Only evaluate text-only questions'
        type: boolean
        default: true
      max_samples:
        description: 'Maximum number of samples to evaluate'
        required: false
        default: '10'
      no_judge:
        description: 'Skip automatic judging'
        type: boolean
        default: false
      num_workers:
        description: 'Number of concurrent workers'
        required: false
        default: '3'
      advanced_options:
        description: 'Advanced options (comma-separated, e.g., "print_streaming,commit_results")'
        required: false
        default: 'commit_results'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 480  # 8 hours max
    permissions:
      contents: write  # Required for git push

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'

    - name: Install uv
      uses: astral-sh/setup-uv@v3

    - name: Install dependencies
      run: uv sync

    - name: Create output directories
      run: |
        mkdir -p results/predictions
        mkdir -p results/judged
        mkdir -p artifacts

    - name: Run benchmark
      env:
        ZENMUX_API_KEY: ${{ secrets.ZENMUX_API_KEY }}
        ZENMUX_BASE_URL: ${{ secrets.ZENMUX_BASE_URL }}
        ZENMUX_API_BASE_URL: ${{ secrets.ZENMUX_API_BASE_URL }}
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        HUGGING_FACE_HUB_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        # Build command arguments
        MODE="${{ github.event.inputs.mode }}"

        # Parse model config for single and filter modes
        MODEL_CONFIG="${{ github.event.inputs.model_config }}"
        MODEL_ARGS=""
        FILTER_ARG=""

        if [ "$MODE" = "single" ]; then
          if [ -z "$MODEL_CONFIG" ]; then
            echo "Error: model_config is required for single mode (format: model_slug:provider_slug)"
            exit 1
          fi
          if [[ "$MODEL_CONFIG" != *":"* ]]; then
            echo "Error: model_config for single mode must be in format 'model_slug:provider_slug'"
            exit 1
          fi
          MODEL_SLUG=$(echo "$MODEL_CONFIG" | cut -d':' -f1)
          PROVIDER_SLUG=$(echo "$MODEL_CONFIG" | cut -d':' -f2)
          MODEL_ARGS="--model-slug $MODEL_SLUG --provider-slug $PROVIDER_SLUG"
        elif [ "$MODE" = "filter" ]; then
          if [ -z "$MODEL_CONFIG" ]; then
            echo "Error: model_config is required for filter mode"
            exit 1
          fi
          FILTER_ARG="--model-filter $MODEL_CONFIG"
        fi

        # Parse exclusion arguments (comma-separated)
        EXCLUDE_ARGS=""
        EXCLUDE_MODELS="${{ github.event.inputs.exclude_models }}"
        if [ -n "$EXCLUDE_MODELS" ]; then
          # Convert comma-separated to space-separated
          EXCLUDE_MODELS_SPACE=$(echo "$EXCLUDE_MODELS" | tr ',' ' ')
          EXCLUDE_ARGS="$EXCLUDE_ARGS --exclude-model $EXCLUDE_MODELS_SPACE"
        fi

        EXCLUDE_PROVIDERS="${{ github.event.inputs.exclude_providers }}"
        if [ -n "$EXCLUDE_PROVIDERS" ]; then
          # Convert comma-separated to space-separated
          EXCLUDE_PROVIDERS_SPACE=$(echo "$EXCLUDE_PROVIDERS" | tr ',' ' ')
          EXCLUDE_ARGS="$EXCLUDE_ARGS --exclude-provider $EXCLUDE_PROVIDERS_SPACE"
        fi

        # Optional arguments
        TEXT_ONLY_ARG=""
        if [ "${{ github.event.inputs.text_only }}" = "true" ]; then
          TEXT_ONLY_ARG="--text-only"
        fi

        NO_JUDGE_ARG=""
        if [ "${{ github.event.inputs.no_judge }}" = "true" ]; then
          NO_JUDGE_ARG="--no-judge"
        fi

        # Parse advanced options (comma-separated)
        ADVANCED_ARGS=""
        ADVANCED_OPTIONS="${{ github.event.inputs.advanced_options }}"
        if [[ "$ADVANCED_OPTIONS" == *"print_streaming"* ]]; then
          ADVANCED_ARGS="$ADVANCED_ARGS --print-streaming"
        fi

        MAX_SAMPLES="${{ github.event.inputs.max_samples || '10' }}"
        NUM_WORKERS="${{ github.event.inputs.num_workers || '3' }}"

        # Run benchmark with all arguments
        uv run python benchmark.py \
          --mode $MODE \
          $MODEL_ARGS \
          $FILTER_ARG \
          $EXCLUDE_ARGS \
          $TEXT_ONLY_ARG \
          $NO_JUDGE_ARG \
          $ADVANCED_ARGS \
          --max-samples $MAX_SAMPLES \
          --num-workers $NUM_WORKERS \
          --output-dir results

    - name: Generate summary report
      run: |
        echo "# ZenMux HLE Benchmark Results" > artifacts/summary.md
        echo "**Date:** $(date)" >> artifacts/summary.md
        echo "**Commit:** $GITHUB_SHA" >> artifacts/summary.md
        echo "**Mode:** ${{ github.event.inputs.mode }}" >> artifacts/summary.md
        echo "**Model Config:** ${{ github.event.inputs.model_config }}" >> artifacts/summary.md
        echo "**Text Only:** ${{ github.event.inputs.text_only }}" >> artifacts/summary.md
        echo "**Max Samples:** ${{ github.event.inputs.max_samples }}" >> artifacts/summary.md
        echo "**Workers:** ${{ github.event.inputs.num_workers }}" >> artifacts/summary.md
        echo "**Exclude Models:** ${{ github.event.inputs.exclude_models }}" >> artifacts/summary.md
        echo "**Exclude Providers:** ${{ github.event.inputs.exclude_providers }}" >> artifacts/summary.md
        echo "**Advanced Options:** ${{ github.event.inputs.advanced_options }}" >> artifacts/summary.md
        echo "" >> artifacts/summary.md

        # Find the timestamped results directory
        RESULTS_DIR=$(find results -name "2*" -type d | head -1)
        if [ -n "$RESULTS_DIR" ]; then
          echo "## Results Directory: $RESULTS_DIR" >> artifacts/summary.md
          echo "" >> artifacts/summary.md

          echo "### Statistics Files" >> artifacts/summary.md
          ls -la $RESULTS_DIR/*.json 2>/dev/null | grep -E "(evaluation|judge|metrics)_statistics" >> artifacts/summary.md || echo "No statistics files found" >> artifacts/summary.md
          echo "" >> artifacts/summary.md

          echo "### Predictions" >> artifacts/summary.md
          ls -la $RESULTS_DIR/predictions/ 2>/dev/null >> artifacts/summary.md || echo "No prediction files found" >> artifacts/summary.md
          echo "" >> artifacts/summary.md

          echo "### Judged Results" >> artifacts/summary.md
          ls -la $RESULTS_DIR/judged/ 2>/dev/null >> artifacts/summary.md || echo "No judged files found" >> artifacts/summary.md
          echo "" >> artifacts/summary.md

          echo "### Logs" >> artifacts/summary.md
          LOG_DIR=$(find logs -name "2*" -type d | head -1)
          if [ -n "$LOG_DIR" ]; then
            ls -la $LOG_DIR/ 2>/dev/null >> artifacts/summary.md || echo "No log files found" >> artifacts/summary.md
          else
            echo "No log directory found" >> artifacts/summary.md
          fi
          echo "" >> artifacts/summary.md

          echo "## Total Size" >> artifacts/summary.md
          du -sh $RESULTS_DIR/ >> artifacts/summary.md || echo "Could not calculate directory size" >> artifacts/summary.md
        else
          echo "No timestamped results directory found" >> artifacts/summary.md
        fi

    - name: Setup Git for commits
      if: contains(github.event.inputs.advanced_options, 'commit_results')
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"

    - name: Commit and push results
      if: contains(github.event.inputs.advanced_options, 'commit_results')
      run: |
        # Check if there are any changes to commit
        if [[ -n $(git status --porcelain) ]]; then
          echo "Changes detected, committing results..."

          # Add results and logs directories
          git add results/ logs/ || true

          # Create commit message with run details
          git commit -m "Add benchmark results from GitHub Actions

          Mode: ${{ github.event.inputs.mode }}
          Model Config: ${{ github.event.inputs.model_config }}
          Text Only: ${{ github.event.inputs.text_only }}
          Max Samples: ${{ github.event.inputs.max_samples }}
          Workers: ${{ github.event.inputs.num_workers }}
          Run ID: ${{ github.run_id }}
          Commit: ${{ github.sha }}

          ðŸ¤– Generated by GitHub Actions"

          # Push to repository
          git push
          echo "Results committed and pushed successfully!"
        else
          echo "No changes to commit."
        fi

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.run_number }}
        path: |
          results/
          artifacts/
        retention-days: 30

    - name: Upload summary
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-summary-${{ github.run_number }}
        path: artifacts/summary.md
        retention-days: 90

  # Optional: Send notification on completion
  notify:
    needs: benchmark
    runs-on: ubuntu-latest
    if: always()
    steps:
    - name: Notify completion
      run: |
        echo "Benchmark completed with status: ${{ needs.benchmark.result }}"
        # Add your notification logic here (Slack, Discord, etc.)